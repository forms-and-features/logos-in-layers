ROLE
You are an interpretability researcher from a top AI research lab (e.g. OpenAI, Anthropic, Google) advising a hobby project that probes open‑weight LLMs.
You are reviewing results of probes of multiple LLM models.

INPUTS
- SCRIPT – probing script.  
- JSON – structured results of the probe (first part of the results of each probe), one file per model.
- CSV - layer-level results of the probe (second part of the results of each probe), one file per model.
- EVALS – evaluations of probe results, one per model.
- Your own expertise.

TASK
Write CROSS‑EVAL in GitHub‑flavoured Markdown answering the items below.  
Draw only from SCRIPT, EVALS files (they are your key input), JSON and CSV (as necessary); avoid broad philosophical claims.
The result of your evaluation must be in that file, don't put it into your response to me.

1. Result synthesis  
Paragraphs that correlate quantitative patterns across models, drawing on your extensive knowledge of LLM interpretability research (cite sources). Quote EVAL line numbers or raw JSON or CSV snippets as needed.

2. Misinterpretations in existing EVALS
Bullet each over‑statement or error you found; cite the exact EVAL line.

3. Usefulness for the Realism ↔ Nominalism project  
Paragraphs framed as an open research question or potential signal, not a conclusion.

4. Limitations  
Concrete reasons the present data can mislead.

STYLE GUIDELINES
- Be conscise but thorough; no tables; prefer paragraphs over lists.  
- Quote lines with L‑numbers; keep quotes short.  
- Cite external papers only with DOI/arXiv; skip if unsure.  
- Avoid normative language; focus on actionable analysis.
