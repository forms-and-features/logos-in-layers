# Evaluation Report: google/gemma-2-27b
**Overview**
Google Gemmaâ€‘2â€‘27B; probe over the Germanyâ†’Berlin prompt using the norm lens. The run captures early copyâ€‘reflex, late semantic collapse at the final layer, high rawâ†”norm divergence, and familyâ€‘typical lastâ€‘layer head misâ€‘calibration.

**Method Sanityâ€‘Check**
The prompt ends exactly with â€œcalled simplyâ€ (no trailing space):
> "Give the city name only, plain text. The capital of Germany is called simply"  [001_layers_baseline/run-latest/output-gemma-2-27b.json:4]

Norm lens and positional handling are enabled and architectureâ€‘aware:
> "use_norm_lens": true, "unembed_dtype": "torch.float32"  [001_layers_baseline/run-latest/output-gemma-2-27b.json:807â€“809]
> "layer0_position_info": "token_only_rotary_model"  [001_layers_baseline/run-latest/output-gemma-2-27b.json:816]

Gold alignment is OK and IDâ€‘based:
> "gold_alignment": "ok"  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1071]
> "gold_answer": { "string": "Berlin", "first_id": 12514, "answer_ids": [12514] }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:2106â€“2114]

Copy/collapse configuration and results are present in diagnostics. Strict copy (Ï„=0.95, k=1, id_subsequence) and soft copy (Ï„=0.5, kâˆˆ{1,2,3}) are defined, with earliest strict and soft copy at L=0 and Î”=46:
> "L_copy": 0, "L_semantic": 46, "delta_layers": 46, "copy_thresh": 0.95, "copy_window_k": 1, "copy_match_level": "id_subsequence"  [001_layers_baseline/run-latest/output-gemma-2-27b.json:938â€“944]
> "L_copy_soft": { "1": 0, "2": null, "3": null }, "delta_layers_soft": { "1": 46, ... }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:956â€“965]
> "copy_detector.strict": { "thresh": 0.95, "k": 1, "L_copy_strict": 0 }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:966â€“971]
> "copy_detector.soft": { "thresh": 0.5, "window_ks": [1,2,3], "L_copy_soft": { "k1": 0, ... } }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:972â€“983]
> "copy_thresholds": { "tau_list": [0.7,0.8,0.9,0.95], "L_copy_strict": {"0.7":0,"0.8":0,"0.9":0,"0.95":0}, "norm_only_flags": { ... all false }, "stability": "mixed" }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:994â€“1021]
> "copy_flag_columns": ["copy_strict@0.95", "copy_strict@0.7", "copy_strict@0.8", "copy_strict@0.9", "copy_soft_k1@0.5", ...]  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1596â€“1603]

Strict copy fires immediately at L0 in the pure CSV (IDâ€‘level subsequence):
> layer=0, copy_collapse=True, copy_strict@{0.95,0.9,0.8,0.7}=True; topâ€‘1 " simply" (p=0.99998)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2]
Earliest softâ€‘copy (k1, Ï„=0.5) is also at L0: "copy_soft_k1@0.5"=True  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2].

Rank and KL summary indices are present (units: bits for KL/entropy):
> "first_kl_below_0.5": null, "first_kl_below_1.0": null, "first_rank_le_1": 46, "first_rank_le_5": 46, "first_rank_le_10": 46  [001_layers_baseline/run-latest/output-gemma-2-27b.json:945â€“949]

Lastâ€‘layer head calibration is off: the finalâ€‘row KL is not ~0 and diagnostics flag it with a temperature estimate; measurement guidance enforces rankâ€‘first reporting:
> final row: "kl_to_final_bits" = 1.1352, "is_answer"=True, "p_top1"=0.9841  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:48]
> { "kl_to_final_bits": 1.1352, "top1_agree": true, "p_top1_lens": 0.9841, "p_top1_model": 0.4226, "temp_est": 2.6102, "kl_after_temp_bits": 0.5665, "warn_high_last_layer_kl": true }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1072â€“1091]
> "measurement_guidance": { "prefer_ranks": true, "suppress_abs_probs": true, "reasons": ["warn_high_last_layer_kl","norm_only_semantics_window","high_lens_artifact_risk"], ... }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:2096â€“2104]

Rawâ€‘vsâ€‘Norm window sanity shows normâ€‘only semantics at the final layer and very large rawâ†”norm divergences:
> "raw_lens_window": { "center_layers": [0,46], "radius": 4, "norm_only_semantics_layers": [46], "max_kl_norm_vs_raw_bits_window": 99.5398 }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1047â€“1069]
> rawlens window CSV (L46): norm p_top1=0.9841 (Berlin), raw p_top1=0.8898 (î«¤); kl_norm_vs_raw_bits=99.5398  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-rawlens-window.csv:20â€“21]
Lens sanity (sampled) flags high artifact risk:
> "raw_lens_check": { "mode": "sample", "summary": { "first_norm_only_semantic_layer": null, "max_kl_norm_vs_raw_bits": 80.1001, "lens_artifact_risk": "high" } }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1534â€“1594]

Negative control and ablation present:
> control_summary: { "first_control_margin_pos": 0, "max_control_margin": 0.9911 }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1628â€“1631]
> ablation_summary: { "L_copy_orig": 0, "L_sem_orig": 46, "L_copy_nf": 3, "L_sem_nf": 46, "delta_L_copy": 3, "delta_L_sem": 0 }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1606â€“1611]

Prism sidecar is compatible (k=512; layers: embed,10,22,33):
> "prism_summary": { "compatible": true, "k": 512, "layers": ["embed",10,22,33] }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:825â€“835]

Tunedâ€‘Lens loaded; skipâ€‘layers sanity warns and regression is noted:
> "tuned_lens": { "path": "/.../tuned_lenses/gemma-2-27b" }  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1104â€“1108]
> "skip_layers_sanity": { "m=2": 475106470164.1723, ... }, "tuned_lens_regression": true  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1431â€“1437]

**Quantitative Findings**
Table (pure nextâ€‘token; prompt_id=pos, prompt_variant=orig): Layer, entropy (bits), topâ€‘1 token. Bold marks the semantic layer (first is_answer=True). For reference, gold_answer.string = â€œBerlinâ€.

| Layer | Entropy (bits) | Top-1 token |
|---:|---:|---|
| 0 | 0.000 |  simply |
| 1 | 8.758 |  |
| 2 | 8.764 |  |
| 3 | 0.886 |  simply |
| 4 | 0.618 |  simply |
| 5 | 8.520 | à¹² |
| 6 | 8.553 | ï•€ |
| 7 | 8.547 | î«¤ |
| 8 | 8.529 | ïŒ |
| 9 | 8.524 | ğ†£ |
| 10 | 8.345 |  dieÅ¿em |
| 11 | 8.493 | ğ†£ |
| 12 | 8.324 | î«¤ |
| 13 | 8.222 | î«¤ |
| 14 | 7.877 | î«¤ |
| 15 | 7.792 | î«¤ |
| 16 | 7.975 |  dieÅ¿em |
| 17 | 7.786 |  dieÅ¿em |
| 18 | 7.300 | Å¿icht |
| 19 | 7.528 |  dieÅ¿em |
| 20 | 6.210 | Å¿icht |
| 21 | 6.456 | Å¿icht |
| 22 | 6.378 |  dieÅ¿em |
| 23 | 7.010 |  dieÅ¿em |
| 24 | 6.497 |  dieÅ¿em |
| 25 | 6.995 |  dieÅ¿em |
| 26 | 6.220 |  dieÅ¿em |
| 27 | 6.701 |  dieÅ¿em |
| 28 | 7.140 |  dieÅ¿em |
| 29 | 7.574 |  dieÅ¿em |
| 30 | 7.330 |  dieÅ¿em |
| 31 | 7.565 |  dieÅ¿em |
| 32 | 8.874 |  zuÅ¿ammen |
| 33 | 6.945 |  dieÅ¿em |
| 34 | 7.738 |  dieÅ¿em |
| 35 | 7.651 |  dieÅ¿em |
| 36 | 7.658 |  dieÅ¿em |
| 37 | 7.572 |  dieÅ¿em |
| 38 | 7.554 |  ãƒ‘ãƒ³ãƒãƒ© |
| 39 | 7.232 |  dieÅ¿em |
| 40 | 8.711 |  å±•æ¿ |
| 41 | 7.082 |  dieÅ¿em |
| 42 | 7.057 |  dieÅ¿em |
| 43 | 7.089 |  dieÅ¿em |
| 44 | 7.568 |  dieÅ¿em |
| 45 | 7.141 |  GeÅ¿ch |
| 46 | 0.118 |  Berlin |

Bold semantic layer: L46 â€” "Berlin" with p_top1=0.9841 and is_answer=True  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:48].

Control margin (JSON): first_control_margin_pos = 0; max_control_margin = 0.9911  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1628â€“1631].

Ablation (noâ€‘filler): L_copy_orig=0, L_sem_orig=46; L_copy_nf=3, L_sem_nf=46; Î”L_copy=3, Î”L_sem=0  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1606â€“1611].

Î”H (bits) = entropy(L_copy) âˆ’ entropy(L_semantic) = 0.00050 âˆ’ 0.11805 = âˆ’0.118  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2,48].
Soft Î”Hâ‚– (k=1) = entropy(L_copy_soft[k]) âˆ’ entropy(L_semantic) = 0.00050 âˆ’ 0.11805 = âˆ’0.118  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2,48].

Confidence milestones (pure): p_top1 > 0.30 at L0; > 0.60 at L0; finalâ€‘layer p_top1 = 0.9841  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2,48].

Rank milestones (diagnostics): rank â‰¤10 at L46; â‰¤5 at L46; â‰¤1 at L46  [001_layers_baseline/run-latest/output-gemma-2-27b.json:947â€“949].

KL milestones (diagnostics): first_kl_below_1.0 = null; first_kl_below_0.5 = null  [001_layers_baseline/run-latest/output-gemma-2-27b.json:945â€“946]. KL is not ~0 at final (1.1352 bits) and head calibration is flagged  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1072â€“1091].

Cosine milestones (JSON): first cos_to_final â‰¥0.2 at L1; â‰¥0.4 at L46; â‰¥0.6 at L46  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1032â€“1036]. Final cos_to_final = 0.99939  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:48].

Depth fractions: L_semantic_frac=1.0; L_copy_strict_frac=0.0; L_copy_soft_k1_frac=0.0  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1039â€“1045].

Copy robustness (threshold sweep): stability = "mixed"; earliest strict copy layer Ï„=0.70 â†’ L0, Ï„=0.95 â†’ L0; norm_only_flags for all Ï„ are false  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1001â€“1019].

Prism Sidecar Analysis
- Early/midâ€‘depth KL: clear reductions vs baseline (e.g., L11: baseline 41.852 bits vs Prism 19.432 bits)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:11; 001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-prism.csv:3].
- Rank milestones (Prism pure): never reaches rank â‰¤10/5/1 (all null) while baseline reaches 46  [001_layers_baseline/run-latest/output-gemma-2-27b.json:839â€“848].
- Sampled depths: L0 baseline topâ€‘1 " simply" vs Prism "assuredly"; Prism cos_to_final negative early (âˆ’0.089)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-prism.csv:2].
- Copy flags: baseline strict copy at L0; Prism shows no copy flags at L0â€“4  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2; 001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-prism.csv:2â€“6].
Verdict: Regressive (big early KL drop without earlier rank milestones; never achieves rankâ‰¤10 under Prism).

Tunedâ€‘Lens Sidecar
- Î”KL medians at percentiles: p25 Î”â‰ˆ+0.054, p50 Î”â‰ˆ+0.334, p75 Î”â‰ˆ+0.342 (KL_norm âˆ’ KL_tuned; positive means tuned slightly better)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:11,24,35; 001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-tuned.csv:24].
- Entropy drift (tuned): at p25/p50/p75, (entropy âˆ’ teacher_entropy_bits) â‰ˆ 5.580, 4.425, 5.203 bits  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-tuned.csv:24].
- Rank milestones: tuned reaches rank â‰¤{10,5,1} at L46 (same as baseline)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-tuned.csv:24].
- Surfaceâ†’meaning: L_surface_to_meaning_norm = 46 (JSON); tuned first answer_mass > echo_mass also at L46  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1021â€“1023; 001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-tuned.csv:24].
- Geometry: tuned cos_to_final â‰¥0.4 at L46 (same as norm)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-tuned.csv:24].
- Coverage (K=50, Ï„â‰ˆ0.33): L_topk_decay_norm=1 (JSON); tuned shows the same earliest drop <0.33  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1027â€“1030; 001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token-tuned.csv:2].
- Norm temperature snapshots: KL_temp@{25,50,75}% â‰ˆ 41.30/41.60/41.51 bits  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1092â€“1103].
Overall: Tunedâ€‘Lens is neutralâ€‘toâ€‘slightly helpful on KL but does not improve rank earliness.

**Qualitative Patterns & Anomalies**
Negative control (Berlin is the capital of): topâ€‘5 do not include â€œBerlinâ€.
> [" Germany", 0.8676], [" the", 0.0650], [" and", 0.0065], [" a", 0.0062], [" Europe", 0.0056]  [001_layers_baseline/run-latest/output-gemma-2-27b.json:14â€“31]

Importantâ€‘word trajectory (records): â€œBerlinâ€ first appears only at the final layer across the three prompt positions; e.g., NEXT after â€œsimplyâ€ shows â€œBerlinâ€ 0.9841 at L46.
> " simply,0.1180, Berlin,0.9841, ..."  [001_layers_baseline/run-latest/output-gemma-2-27b-records.csv:806]
Earlier layers are dominated by historical/orthographic artifacts (e.g., â€œdieÅ¿emâ€, â€œÅ¿ichtâ€, â€œGeÅ¿châ€) rather than country/capital semantics  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:10,18,45].

Collapseâ€‘layer stability without â€œoneâ€‘wordâ€ instruction: Ablation shows L_sem unchanged (46) while copy shifts later (L_copy 0â†’3), suggesting filler removal disrupts copyâ€‘reflex but not the eventual semantic collapse  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1606â€“1611].

Restâ€‘mass sanity: early layers have very high rest_mass (e.g., L1 â‰ˆ 0.982), decaying by the final layer (â‰ˆ2.0eâ€‘7), indicating sharpening and topâ€‘k concentration near collapse  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:3,48].

Rotation vs amplification: cos_to_final rises only late (â‰¥0.4 and â‰¥0.6 at L46), while KL to the final head stays high throughout and remains â‰ˆ1.14 bits even at L46, indicating an â€œearly direction, late calibrationâ€ picture with finalâ€‘head calibration issues  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1032â€“1036,1072â€“1091].

Head calibration (final layer): diagnostics estimate tempâ‰ˆ2.61 and reduce KL after temp to â‰ˆ0.567 bits, consistent with Gemma family behavior; rely on rankâ€‘based milestones for crossâ€‘model comparisons  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1072â€“1091].

Lens sanity: sampled rawâ€‘vsâ€‘norm shows extreme divergences (maxâ‰ˆ80.10 bits), with raw often assigning very high mass to nonâ€‘semantic tokens midâ€‘stack; within the window, the final layer is normâ€‘only semantic  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1534â€“1594,1047â€“1069]. Example sample:
> L12: kl_norm_vs_raw_bits=33.687; p_top1_norm=0.0144 vs p_top1_raw=0.3918; answer_rank_norm=240631 vs raw=402  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1551â€“1561].

Temperature robustness: T=0.1 â†’ â€œBerlinâ€ pâ‰ˆ0.9898 (entropyâ‰ˆ0.082); T=2.0 â†’ â€œBerlinâ€ pâ‰ˆ0.049 (entropyâ‰ˆ12.631)  [001_layers_baseline/run-latest/output-gemma-2-27b.json:670â€“676,737â€“744,738â€“739].

Checklist
- RMS lens? âœ“  [001_layers_baseline/run-latest/output-gemma-2-27b.json:810â€“814]
- LayerNorm bias removed? âœ“ (RMSNorm; â€œnot_needed_rms_modelâ€)  [001_layers_baseline/run-latest/output-gemma-2-27b.json:811â€“813]
- Entropy rise at unembed? âœ— (final entropy low; teacher entropy â‰ˆ2.886)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:48]
- FP32 unâ€‘embed promoted? âœ“ (casting to fp32 before unembed; unembed_dtype fp32)  [001_layers_baseline/run-latest/output-gemma-2-27b.json:808â€“809,815]
- Punctuation / markup anchoring? âœ“ (nonâ€‘Latin/markup tokens midâ€‘stack)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:32,40]
- Copyâ€‘reflex? âœ“ (strict and soft at L0)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2]
- Grammatical filler anchoring? âœ“ (topâ€‘1 â€œ simplyâ€ in L0/L3/L4)  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:2,5,6]

**Limitations & Data Quirks**
- High rest_mass in early layers reflects topâ€‘k coverage limits, not fidelity; interpret via KL/entropy and ranks withinâ€‘model only  [001_layers_baseline/run-latest/output-gemma-2-27b-pure-next-token.csv:3].
- KL is lensâ€‘sensitive; rawâ€‘vsâ€‘norm shows large divergences (80â€“100 bits in window). Treat any preâ€‘final â€œearly semanticsâ€ cautiously; prefer rank milestones  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1047â€“1069,1534â€“1594].
- Finalâ€‘head calibration (warn_high_last_layer_kl=true) means final probabilities are not crossâ€‘family comparable; use rank milestones and KL thresholds within model  [001_layers_baseline/run-latest/output-gemma-2-27b.json:1072â€“1091,2096â€“2104].
- Surfaceâ€‘mass and coverage trends can be tokenizerâ€‘dependent; avoid crossâ€‘model absolute comparisons.

**Model Fingerprint**
Gemmaâ€‘2â€‘27B: strict copy at L0; semantic collapse at L46; final KLâ‰ˆ1.14 bits; â€œBerlinâ€ stabilizes only at the last layer.

---
Produced by OpenAI GPT-5 
*Run executed on: 2025-09-29 23:35:16*
